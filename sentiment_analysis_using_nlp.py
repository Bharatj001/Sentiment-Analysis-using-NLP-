# -*- coding: utf-8 -*-
"""Sentiment Analysis Using NLP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KT6Vhrg3RcSn8CT0Eox8ds6bwJaOObIP

Install Libraries
"""

# Install the transformers library
!pip install transformers -q

import pandas as pd
import numpy as np

# For plotting
import matplotlib.pyplot as plt
import seaborn as sns

# Set plot style
sns.set_style('whitegrid')

"""UPLOAD DATA SET"""

# Define the file name
file_path = 'googleplaystore_user_reviews.csv'

# Load the CSV file into a DataFrame
df = pd.read_csv('/content/googleplaystore_user_reviews.csv')

# Display the first 5 rows of the DataFrame
print("First 5 rows of the dataset:")
display(df.head())

# Get a concise summary of the DataFrame
print("DataFrame Information:")
df.info()

# Count the number of missing values in each column
print("\nMissing values in each column:")
print(df.isnull().sum())

"""Preprocessing"""

# Create a new dataframe, dropping rows where 'Translated_Review' or 'Sentiment' is missing.
df_clean = df.dropna(subset=['Translated_Review', 'Sentiment'])

# Let's check the shape of the original and the cleaned dataframes
print("Shape of original dataframe:", df.shape)
print("Shape of dataframe after dropping NA:", df_clean.shape)

# Verify that there are no more missing values in these columns
print("\nMissing values after cleaning:")
print(df_clean[['Translated_Review', 'Sentiment']].isnull().sum())

# Create a new dataframe with just the columns we need
df_final = df_clean[['Translated_Review', 'Sentiment']].copy()

# Rename the columns for easier access
df_final.rename(columns={'Translated_Review': 'text', 'Sentiment': 'sentiment'}, inplace=True)

# Display the first 5 rows of our new final dataframe
display(df_final.head())

# Check the counts of each sentiment category
print("Sentiment Distribution:")
print(df_final['sentiment'].value_counts())

# Visualize the distribution using a count plot
plt.figure(figsize=(8, 5))
sns.countplot(x='sentiment', data=df_final, order=['Positive', 'Neutral', 'Negative'])
plt.title('Distribution of Sentiments')
plt.xlabel('Sentiment')
plt.ylabel('Number of Reviews')
plt.show()

# Create a dictionary to map sentiment labels to numbers
sentiment_map = {
    'Negative': 0,
    'Neutral': 1,
    'Positive': 2
}

# Apply this mapping to the 'sentiment' column to create a new 'label' column
df_final['label'] = df_final['sentiment'].map(sentiment_map)

# Display the dataframe to confirm the new column has been added correctly
display(df_final.head())

"""Tokenization."""

from transformers import BertTokenizer

# Define the pre-trained model name
PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'

# Load the BERT tokenizer
tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)

# Take a sample review
sample_text = df_final['text'].iloc[5]
print(f'Original Text: {sample_text}')
print('-' * 20)

# Tokenize the sample text
encoding = tokenizer.encode_plus(
  sample_text,
  max_length=32,           # Max length to pad/truncate
  add_special_tokens=True, # Add '[CLS]' and '[SEP]'
  return_token_type_ids=False,
  pad_to_max_length=True,
  return_attention_mask=True,
  return_tensors='pt',     # Return PyTorch tensors
)

# Print the results
print('Tokens:', tokenizer.convert_ids_to_tokens(encoding['input_ids'][0]))
print('Input IDs:', encoding['input_ids'][0])
print('Attention Mask:', encoding['attention_mask'][0])

# Tokenize all reviews and get the length of each
token_lens = []
for txt in df_final['text']:
  tokens = tokenizer.encode(txt, max_length=512, truncation=True)
  token_lens.append(len(tokens))

# Plot the distribution of token lengths
sns.histplot(token_lens)
plt.xlim([0, 256]);
plt.xlabel('Token count');
plt.title('Distribution of Token Counts in Reviews');

"""Tokenize Entire Dataset"""

import torch
from tqdm.notebook import tqdm

# Set the maximum length
MAX_LEN = 160

# Convert the text and label columns to lists
texts = df_final['text'].tolist()
labels = df_final['label'].tolist()

# Tokenize the texts
encoding = tokenizer(
    texts,
    add_special_tokens=True,
    max_length=MAX_LEN,
    padding='max_length',
    truncation=True,
    return_attention_mask=True,
    return_tensors='pt'
)

# The tokenizer returns a dictionary-like object. We can access the tensors like this:
input_ids = encoding['input_ids']
attention_masks = encoding['attention_mask']
labels = torch.tensor(labels) # Convert labels to a tensor

# Check the shape of our tensors
print(f'Input IDs Shape: {input_ids.shape}')
print(f'Attention Masks Shape: {attention_masks.shape}')
print(f'Labels Shape: {labels.shape}')

"""Spliting  Data Training and Validation Sets"""

from sklearn.model_selection import train_test_split

# Use 90% for training and 10% for validation.
train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(
    input_ids,
    labels,
    attention_masks,
    random_state=2024,   # A seed for reproducible results
    test_size=0.1,       # 10% of data goes to the validation set
    stratify=labels      # Preserve the same distribution of labels in both sets
)


# Let's check the shapes of our new sets
print("Training Inputs Shape:", train_inputs.shape)
print("Validation Inputs Shape:", validation_inputs.shape)
print("Training Labels Shape:", train_labels.shape)
print("Validation Labels Shape:", validation_labels.shape)
print("Training Masks Shape:", train_masks.shape)
print("Validation Masks Shape:", validation_masks.shape)

from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler

# Define the batch size
BATCH_SIZE = 16

# Create a TensorDataset for the training data
train_dataset = TensorDataset(train_inputs, train_masks, train_labels)

# Create a DataLoader for the training set.
# We'll use a RandomSampler to select batches randomly.
train_dataloader = DataLoader(
            train_dataset,
            sampler=RandomSampler(train_dataset),
            batch_size=BATCH_SIZE
        )

# Create a TensorDataset for the validation data
validation_dataset = TensorDataset(validation_inputs, validation_masks, validation_labels)

# Create a DataLoader for the validation set.
# For validation, the order doesn't matter, so we use a SequentialSampler.
validation_dataloader = DataLoader(
            validation_dataset,
            sampler=SequentialSampler(validation_dataset),
            batch_size=BATCH_SIZE
        )

# Get one batch of training data
batch_input_ids, batch_attention_mask, batch_labels = next(iter(train_dataloader))

print(f'Batch of Input IDs has shape: {batch_input_ids.shape}')
print(f'Batch of Attention Masks has shape: {batch_attention_mask.shape}')
print(f'Batch of Labels has shape: {batch_labels.shape}')

"""Build the Model"""

from transformers import BertForSequenceClassification

# Load the BertForSequenceClassification model
model = BertForSequenceClassification.from_pretrained(
    PRE_TRAINED_MODEL_NAME,      # Use the 12-layer BERT model, with an uncased vocab.
    num_labels = 3,              # The number of output labels: 3 for our multi-class task.
    output_attentions = False,   # Whether the model returns attentions weights.
    output_hidden_states = False, # Whether the model returns all hidden-states.
)

# Tell PyTorch to run this model on the GPU (if available).
# In Colab, you can enable this under Runtime > Change runtime type > Hardware accelerator > GPU.
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

print(f'The model is now loaded on: {device}')

from torch.optim import AdamW
from transformers.optimization import get_linear_schedule_with_warmup


# The optimizer is what updates the model's weights to minimize the loss.
optimizer = AdamW(model.parameters(),
                  lr = 2e-5, # Learning rate (a common value for fine-tuning BERT)
                  eps = 1e-8 # Adam's epsilon
                )

# We'll train for 3 epochs.
EPOCHS = 3

# The total number of training steps is [number of batches] x [number of epochs].
total_steps = len(train_dataloader) * EPOCHS

# Create a learning rate scheduler.
# This will decrease the learning rate linearly from the initial lr set in the optimizer to 0.
scheduler = get_linear_schedule_with_warmup(optimizer,
                                            num_warmup_steps = 0, # Default value
                                            num_training_steps = total_steps)

import time
import datetime

# Function to calculate the accuracy of our predictions vs labels
def flat_accuracy(preds, labels):
    pred_flat = np.argmax(preds, axis=1).flatten()
    labels_flat = labels.flatten()
    return np.sum(pred_flat == labels_flat) / len(labels_flat)

# Function to format time elapsed in hh:mm:ss
def format_time(elapsed):
    '''
    Takes a time in seconds and returns a string in hh:mm:ss
    '''
    # Round to the nearest second.
    elapsed_rounded = int(round((elapsed)))

    # Format as hh:mm:ss
    return str(datetime.timedelta(seconds=elapsed_rounded))

"""Training the Model"""

import random
import numpy as np
import time
import datetime

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def flat_accuracy(preds, labels):
    pred_flat = np.argmax(preds, axis=1).flatten()
    labels_flat = labels.flatten()
    return np.sum(pred_flat == labels_flat) / len(labels_flat)

def format_time(elapsed):
    '''
    Takes a time in seconds and returns a string hh:mm:ss
    '''
    # Round to the nearest second.
    elapsed_rounded = int(round((elapsed)))

    # Format as hh:mm:ss
    return str(datetime.timedelta(seconds=elapsed_rounded))

# Set the seed for reproducibility.
seed_val = 42

random.seed(seed_val)
np.random.seed(seed_val)
torch.manual_seed(seed_val)
torch.cuda.manual_seed_all(seed_val)

# We'll store the training statistics
training_stats = []

# Measure the total training time for the whole run.
total_t0 = time.time()

# For each epoch...
for epoch_i in range(0, EPOCHS):

    # ========================================
    #               Training
    # ========================================

    # Perform one full pass over the training set.
    print("")
    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))
    print('Training...')

    # Measure how long the training epoch takes.
    t0 = time.time()

    # Reset the total loss for this epoch.
    total_train_loss = 0

    # Put the model into training mode.
    model.train()

    # For each batch of training data...
    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):

        # Progress update every 40 batches.
        if step % 40 == 0 and not step == 0:
            # Calculate elapsed time in minutes.
            elapsed = format_time(time.time() - t0)

            # Report progress.
            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))

        # Unpack this training batch from our dataloader.
        #
        # As unpacked here, it consists of three PyTorch tensors:
        # - batch[0]: input ids
        # - batch[1]: attention masks
        # - batch[2]: labels
        b_input_ids = batch[0].to(device)
        b_input_mask = batch[1].to(device)
        b_labels = batch[2].to(device)

        # Clear any previously calculated gradients before performing a backward pass.
        model.zero_grad()

        # Perform a forward pass (evaluate the model on this training batch).
        # The documentation for this `model` function is here:
        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification
        # It returns different things depending on what arguments were given.
        # In our case the return value will be below rather than a Tuple because we've given labels.
        # `loss` is the cross entropy loss between the model's logits and the labels.
        # `logits` are the model's output scores for each class.
        result = model(b_input_ids,
                       token_type_ids=None,
                       attention_mask=b_input_mask,
                       labels=b_labels,
                       return_dict=True)

        loss = result.loss
        logits = result.logits

        # Accumulate the training loss over all of the batches so that we can
        # calculate the average loss at the end, and print the report each epoch.
        total_train_loss += loss.item()

        # Perform a backward pass to calculate the gradients.
        loss.backward()

        # Clip the norm of the gradients to 1.0.
        # This is to help prevent the "exploding gradients" problem.
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)

        # Update parameters and take a step using the computed gradient.
        # The optimizer dictates the step size based on the gradients.
        optimizer.step()

        # Update the learning rate.
        scheduler.step()

    # Calculate the average loss over all of the batches.
    avg_train_loss = total_train_loss / len(train_dataloader)

    # Measure how long this epoch took.
    training_time = format_time(time.time() - t0)

    print("")
    print("  Average training loss: {0:.2f}".format(avg_train_loss))
    print("  Training epoch took: {:}".format(training_time))

    # ========================================
    #               Validation
    # ========================================
    # After the completion of each training epoch, measure our performance on
    # our validation set.

    print("")
    print("Running Validation...")

    t0 = time.time()

    # Put the model in evaluation mode--the dropout layers behave differently
    # during evaluation.
    model.eval()

    # Tracking variables
    total_eval_accuracy = 0
    total_eval_loss = 0
    nb_eval_steps = 0
    all_preds = []
    all_labels = []

    # Evaluate data for one epoch
    for batch in validation_dataloader:

        # Unpack this training batch from our dataloader.
        #
        # As unpacked here, it consists of three PyTorch tensors:
        # - batch[0]: input ids
        # - batch[1]: attention masks
        # - batch[2]: labels
        b_input_ids = batch[0].to(device)
        b_input_mask = batch[1].to(device)
        b_labels = batch[2].to(device)

        # Tell pytorch not to compute gradients during our forward pass,
        # since this is just for evaluation.
        with torch.no_grad():

            # Forward pass, calculate logit predictions.
            # token_type_ids is not used here
            result = model(b_input_ids,
                           token_type_ids=None,
                           attention_mask=b_input_mask,
                           labels=b_labels,
                           return_dict=True)

        loss = result.loss
        logits = result.logits

        # Accumulate the validation loss.
        total_eval_loss += loss.item()

        # Move logits and labels to CPU
        logits = logits.detach().cpu().numpy()
        label_ids = b_labels.to('cpu').numpy()

        # Store predictions and labels for metrics calculation
        all_preds.extend(np.argmax(logits, axis=1).flatten())
        all_labels.extend(label_ids.flatten())


    # Calculate the average loss over all of the batches.
    avg_val_loss = total_eval_loss / len(validation_dataloader)

    # Report the number of batches
    print("  Validation Loss: {0:.2f}".format(avg_val_loss))


    # Calculate evaluation metrics (accuracy, precision, recall, f1)
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='weighted')
    recall = recall_score(all_labels, all_preds, average='weighted')
    f1 = f1_score(all_labels, all_preds, average='weighted')


    print("  Accuracy: {0:.4f}".format(accuracy))
    print("  Precision: {0:.4f}".format(precision))
    print("  Recall: {0:.4f}".format(recall))
    print("  F1 Score: {0:.4f}".format(f1))


    # Measure how long the validation run took.
    validation_time = format_time(time.time() - t0)

    print("  Validation took: {:}".format(validation_time))

    # Record the stats for this epoch.
    training_stats.append(
        {
            'epoch': epoch_i + 1,
            'Training Loss': avg_train_loss,
            'Valid. Loss': avg_val_loss,
            'Valid. Accur.': accuracy,
            'Training Time': training_time,
            'Validation Time': validation_time
        }
    )

print("")
print("Training complete!")

print("Total training took {:} (h:mm:ss)".format(format_time(time.time()-total_t0)))

# Create a DataFrame from our training statistics.
df_stats = pd.DataFrame(data=training_stats)

# Use the 'epoch' as the row index.
df_stats = df_stats.set_index('epoch')

# A plot of the training and validation loss curves.
plt.figure(figsize=(12, 6))
sns.lineplot(data=df_stats, x=df_stats.index, y='Training Loss', label="Training")
sns.lineplot(data=df_stats, x=df_stats.index, y='Valid. Loss', label="Validation")
plt.title("Training & Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.xticks(df_stats.index)
plt.show()

# A plot of the validation accuracy.
plt.figure(figsize=(12, 6))
sns.lineplot(data=df_stats, x=df_stats.index, y='Valid. Accur.', label="Validation Accuracy")
plt.title("Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.xticks(df_stats.index)
plt.show()

# Create a reverse mapping from numerical labels to sentiment strings
sentiment_map_rev = {v: k for k, v in sentiment_map.items()}

def predict_sentiment(text):
    # Set the model to evaluation mode
    model.eval()

    # Tokenize the input text
    encoding = tokenizer.encode_plus(
      text,
      add_special_tokens=True,
      max_length=MAX_LEN,
      return_token_type_ids=False,
      pad_to_max_length=True,
      truncation=True,
      return_attention_mask=True,
      return_tensors='pt',
    )

    # Move tensors to the same device as the model
    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)

    # Get the model's prediction
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
        logits = outputs.logits

    # Move logits to CPU, convert to numpy, and get the prediction
    prediction = np.argmax(logits.detach().cpu().numpy(), axis=1)[0]

    # Map the prediction back to the sentiment string
    return sentiment_map_rev[prediction]

# Test a positive review
review1 = "This app is absolutely amazing! The interface is clean and the features are top-notch."
print(f'Review: "{review1}"')
print(f'Predicted Sentiment: {predict_sentiment(review1)}\n')

# Test a negative review
review2 = "The latest update is a disaster. It's full of bugs and crashes every five minutes."
print(f'Review: "{review2}"')
print(f'Predicted Sentiment: {predict_sentiment(review2)}\n')

# Test a neutral review
review3 = "It's an okay app. It does what it says it will do, but there is nothing special about it."
print(f'Review: "{review3}"')
print(f'Predicted Sentiment: {predict_sentiment(review3)}\n')

import os

# Define the output directory
output_dir = './bert-sentiment-model/'

# Create the directory if it doesn't exist
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

print(f"Saving model to {output_dir}")

# Save the trained model, configuration, and tokenizer
model.save_pretrained(output_dir)
tokenizer.save_pretrained(output_dir)

# You can now find these files in the file-explorer on the left side of Colab.
# You can download them to your local machine from there.